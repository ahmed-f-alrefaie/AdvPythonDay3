{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3cba52f-b564-4e4d-9e61-6678cf5449c8",
   "metadata": {},
   "source": [
    "# Parallelizing your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb666aec-b5e1-4912-a6ea-2af2a6587670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3051e15-550f-446c-83a2-1748d9035393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp    \n",
    "mp.set_start_method(\"fork\")    # Only needed for Jupyter, do not do this in python code itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb959a9-dc16-4560-a7c2-e96ee3a81e2e",
   "metadata": {},
   "source": [
    "Often times we want to perform multiple task simulatenous and leverage multiple cores.\n",
    "\n",
    "Previously we would use the `threading` library or `multiprocessing` library to achieve this but\n",
    "nowadays these are pretty terrible to use. For multiple reasons but not limited to:\n",
    "    \n",
    "    - Script freezing due to deadlock\n",
    "    - Zombie python processes appearing\n",
    "    - Script not finishing at the end\n",
    "    - All other sadness\n",
    "\n",
    "\n",
    "Instead we will use the `concurrent.futures` module to make this experience as smooth as possible. Lets try it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c38abe1-9f78-44db-9d97-fee9ed30108f",
   "metadata": {},
   "source": [
    "Python has to parallel execution modules. `threading` and `multiprocessing`. Threading runs parallel jobs in the same python process while Multiprocessing spawns new python processes.\n",
    "\n",
    "The difference comes from the Global Interpretor Lock. Within a single python process, only one python task can be run at the same time. However if the task release this lock then another task can run. Often time, reading things from file or certain functions (like numba with `nogil`) will release the lock and allow concurrent processes.\n",
    "\n",
    "Multiproccessing overcomes this by creating a new python process and running tasks there. However it requires explicitly sending data to that process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0c190c-2fb4-4008-a19f-f238c4ddb8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf35ee3-6b3e-4eb7-9534-d6c74172414f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5440211108893698\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=1) as e:\n",
    "    futures = e.submit(f,10)\n",
    "    print(futures.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4eca30-2553-4e64-b5a8-2ab356eddc2b",
   "metadata": {},
   "source": [
    "We can submit a bunch more tasks if we want as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ecbc489-00a8-46db-9cc8-b910096c1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = np.arange(0,10)\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as e:\n",
    "    futures = [e.submit(f,x) for x in tasks]\n",
    "    all_values = [x.result() for x in futures]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228ba041-12dc-4093-9667-eb93d692cdbe",
   "metadata": {},
   "source": [
    "Now this can be a bit laborious for large set of tasks, what we can instead do is leverage the `map` function and map our task across inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed9a841c-c701-4974-945f-ae6e189abfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.8414709848078965\n",
      "0.9092974268256817\n",
      "0.1411200080598672\n",
      "-0.7568024953079282\n",
      "-0.9589242746631385\n",
      "-0.27941549819892586\n",
      "0.6569865987187891\n",
      "0.9893582466233818\n",
      "0.4121184852417566\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=8) as e:\n",
    "    for x in e.map(f, tasks):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "afaa43b9-34b9-4318-8b07-62ed9b798f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.84147098  0.90929743  0.14112001 -0.7568025  -0.95892427\n",
      " -0.2794155   0.6569866   0.98935825  0.41211849]\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(max_workers=8) as e:\n",
    "    res = np.array(list(e.map(f,tasks)))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd4855-ad4e-4f32-843d-7164099ad70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95c631ba-c8eb-4148-bb5d-5afd10d1dbcc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76cc89f1-dda3-48f9-a42c-b7efc6e80bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def hash_one(n):\n",
    "    \"\"\"A somewhat CPU-intensive task.\"\"\"\n",
    "\n",
    "    for i in range(1, n):\n",
    "        hashlib.pbkdf2_hmac(\"sha256\", b\"password\", b\"salt\", i * 10000)\n",
    "\n",
    "    return \"done\"\n",
    "\n",
    "\n",
    "def hash_all(n):\n",
    "    \"\"\"Function that does hashing in serial.\"\"\"\n",
    "\n",
    "    for i in range(n):\n",
    "        hsh = hash_one(n)\n",
    "\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42736da-c1c3-41a2-a4e6-5f1c2915e529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11 s ± 31.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hash_all(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc30442-e03d-49bc-a266-82c4c3090fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_all_process(n):\n",
    "    \"\"\"Function that does hashing in serial.\"\"\"\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=4) as executor:\n",
    "        for arg, res in zip(range(n), executor.map(hash_one, range(n), chunksize=2)):\n",
    "            pass\n",
    "\n",
    "    return \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceeda364-ab51-442b-bcc6-56a7768c8856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 ms ± 2.26 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit hash_all_process(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ee9db-94d8-4a30-8abc-f2034fa81cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
